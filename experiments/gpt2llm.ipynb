{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8897d8db",
      "metadata": {},
      "source": [
        "# GPT-2 Instruction Fine-Tuning (LLM)\n",
        "\n",
        "This notebook fine-tunes a pretrained GPT-2 model on instruction-following data. It covers:\n",
        "\n",
        "- **Instruction dataset**: Loading and formatting instruction/input/output triples\n",
        "- **Supervised fine-tuning (SFT)**: Training on (instruction, response) pairs\n",
        "- **Evaluation**: Generating responses and comparing to ground truth\n",
        "- **LLM-as-judge**: Using a separate LLM (Ollama/Llama) to score model outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24383c1c",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Add project root directory to Python path so project modules can be imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eaa37d2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add project root directory to Python path\n",
        "sys.path.append(os.path.abspath(\"..\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1a2b3c4",
      "metadata": {},
      "source": [
        "## Imports\n",
        "\n",
        "Import torch, pandas, tiktoken, and project modules (config, gpt, dataset, utils, pretrained, gpt2llm_functions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "80f68aeb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from llm.config import GPT_CONFIG_124M\n",
        "from llm.gpt import *\n",
        "from llm.dataset import *\n",
        "from llm.utils import *\n",
        "from llm.pretrained import *\n",
        "from llm.gpt2llm_functions import *\n",
        "\n",
        "import pandas as pd\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1671ac08",
      "metadata": {},
      "source": [
        "## Load Instruction Dataset\n",
        "\n",
        "Load instruction-data.json via `download_and_load_file`; prints number of entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "21032f96",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "file_path = \"gpt2llm_data/instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e8a106",
      "metadata": {},
      "source": [
        "## Inspect Data Format\n",
        "\n",
        "Print an example entry to show instruction/input/output structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c8d7f6f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0428daad",
      "metadata": {},
      "source": [
        "## Format Model Input\n",
        "\n",
        "Format an entry with `format_input()` and print the full prompt (instruction + input + desired response)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e0abd465",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e67634",
      "metadata": {},
      "source": [
        "## Train / Validation / Test Split\n",
        "\n",
        "Split data 85% train, 10% test, 5% validation by index slicing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "35f3b3f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "train_portion = int(len(data) * 0.85)  \n",
        "test_portion = int(len(data) * 0.1)    \n",
        "val_portion = len(data) - train_portion - test_portion \n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "990cba72",
      "metadata": {},
      "source": [
        "## Tokenizer\n",
        "\n",
        "Initialize GPT-2 BPE tokenizer; verify `<|endoftext|>` encodes to [50256]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d7d006b0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0a3051",
      "metadata": {},
      "source": [
        "## Device Selection\n",
        "\n",
        "Select device: CUDA, MPS (Apple Silicon), or CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "25d37b8a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
        "    if (major, minor) >= (2, 9):\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dd1dfbf",
      "metadata": {},
      "source": [
        "## Custom Collate Function\n",
        "\n",
        "Create `customized_collate_fn` via `partial` with device and allowed_max_length=1024."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9f0de44f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collate function with device and max_length fixed for DataLoader\n",
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc06b7f",
      "metadata": {},
      "source": [
        "## Create Train DataLoader\n",
        "\n",
        "Create InstructionDataset and train DataLoader (batch_size=8, shuffle=True, drop_last=True)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ece8159e",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d06549a",
      "metadata": {},
      "source": [
        "## Validation and Test DataLoaders\n",
        "\n",
        "Create val and test DataLoaders with InstructionDataset (shuffle=False, drop_last=False)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2709247d",
      "metadata": {},
      "outputs": [],
      "source": [
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05141988",
      "metadata": {},
      "source": [
        "## Inspect Batch Shapes\n",
        "\n",
        "Print input and target shapes for each train batch (batch_size, seq_len)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e4006751",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c80c42f6",
      "metadata": {},
      "source": [
        "## Load Pretrained GPT-2 Model\n",
        "\n",
        "Download pretrained weights via `download_and_load_gpt2`, load into GPT with `load_weights_into_gpt`, set eval mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bb5b8c91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
            "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
            "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
            "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 1024)\n",
              "  (pos_emb): Embedding(1024, 1024)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     \n",
        "    \"context_length\": 1024,  \n",
        "    \"drop_rate\": 0.0,        \n",
        "    \"qkv_bias\": True         \n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e6f7g8",
      "metadata": {},
      "source": [
        "## Zero-Shot Generation (Before Fine-Tuning)\n",
        "\n",
        "Generate text for a validation example with `generate()`. Pretrained model may not follow the instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "60b9dd62",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "498234cc",
      "metadata": {},
      "source": [
        "## Extract Response from Generated Text\n",
        "\n",
        "Remove input prompt and '### Response:' from generated_text; print the extracted model response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0e72efab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e83d8a7",
      "metadata": {},
      "source": [
        "## Baseline Loss (Before Fine-Tuning)\n",
        "\n",
        "Compute train and validation loss on pretrained model (5 batches each) with `torch.no_grad()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "aa45f196",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 3.825895166397095\n",
            "Validation loss: 3.7619204044342043\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "863a53f8",
      "metadata": {},
      "source": [
        "## Supervised Fine-Tuning\n",
        "\n",
        "Train with AdamW via `train_model_simple`. Logs loss and sample generations at eval intervals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bdd1e518",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.945\n",
            "Ep 1 (Step 000015): Train loss 0.856, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.753, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.798, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
            "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.764\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
            "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.667\n",
            "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
            "Ep 2 (Step 000125): Train loss 0.450, Val loss 0.687\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
            "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.676\n",
            "Ep 2 (Step 000155): Train loss 0.412, Val loss 0.676\n",
            "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.683\n",
            "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.671\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.658\n",
            "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.660\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.651\n",
            "Ep 2 (Step 000195): Train loss 0.330, Val loss 0.638\n",
            "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.638\n",
            "Ep 2 (Step 000205): Train loss 0.351, Val loss 0.634\n",
            "Ep 2 (Step 000210): Train loss 0.366, Val loss 0.632\n",
            "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.636\n",
            "Ep 2 (Step 000220): Train loss 0.300, Val loss 0.648\n",
            "Ep 2 (Step 000225): Train loss 0.348, Val loss 0.660\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.657\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Training completed in 33.15 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46398a65",
      "metadata": {},
      "source": [
        "## Plot Training Loss\n",
        "\n",
        "Plot train and validation loss vs epochs and tokens; save to gpt2llm_images/loss-plot.pdf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7a675d3c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
        "plt.savefig(\"gpt2llm_images/loss-plot.pdf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b41808e6",
      "metadata": {},
      "source": [
        "## Evaluate Model Responses\n",
        "\n",
        "Generate responses on first 3 test examples; compare model output to correct answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4eb1a49a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a746b109",
      "metadata": {},
      "source": [
        "## Generate Responses for Full Test Set\n",
        "\n",
        "Run inference on all test examples and save results (with model_response) to instruction-data-with-response.json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "86e4efc5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 110/110 [22:37<00:00, 12.34s/it] \n"
          ]
        }
      ],
      "source": [
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"gpt2llm_data/instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d4cdfd",
      "metadata": {},
      "source": [
        "## Inspect Test Data with Model Response\n",
        "\n",
        "Print first test entry with model_response field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1c58a959",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h9i0j1k2",
      "metadata": {},
      "source": [
        "## Save Fine-Tuned Model Weights\n",
        "\n",
        "Save model state dict to gpt2llm_model_weights/{model}-sft.pth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "95a013b6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as gpt2llm_model_weights/gpt2-medium355M-sft.pth\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"gpt2llm_model_weights/{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebaf2883",
      "metadata": {},
      "source": [
        "## Check Ollama Running\n",
        "\n",
        "Verify Ollama is running via psutil; required for LLM-as-judge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5b063829",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a522cd2a",
      "metadata": {},
      "source": [
        "## Query Ollama (Llama) API\n",
        "\n",
        "Define `query_model` to send prompts to local Ollama server; demo with \"What do Llamas eat?\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "08436c63",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
            "\n",
            "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
            "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
            "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
            "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
            "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
            "\n",
            "In the wild, llamas might also eat:\n",
            "\n",
            "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
            "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
            "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
            "\n",
            "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
          ]
        }
      ],
      "source": [
        "import requests  \n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model=\"llama3\",\n",
        "\n",
        "    url=\"http://localhost:11434/api/chat\"\n",
        "):\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     \n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "    with requests.post(url, json=data, stream=True, timeout=30) as r:\n",
        "        r.raise_for_status()\n",
        "        response_data = \"\"\n",
        "        for line in r.iter_lines(decode_unicode=True):\n",
        "            if not line:\n",
        "                continue\n",
        "            response_json = json.loads(line)\n",
        "            if \"message\" in response_json:\n",
        "                response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "\n",
        "model = \"llama3\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130bb5af",
      "metadata": {},
      "source": [
        "## LLM-as-Judge: Sample Scoring\n",
        "\n",
        "For 3 test examples, ask the judge LLM to score the model response (0100) given input and correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f7a659cf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> I'd rate the model response \"The car is as fast as a bullet.\" an 85 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The response uses a simile correctly, comparing the speed of the car to something else (in this case, a bullet).\n",
            "* The comparison is relevant and makes sense, as bullets are known for their high velocity.\n",
            "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
            "\n",
            "The only reason I wouldn't give it a perfect score is that some people might not immediately think of a bullet when they hear \"fast\", whereas lightning is often an intuitive comparison for speed. However, \"a bullet\" is still a good choice and effectively conveys the idea that the car is very quick!\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "\n",
            "Score:\n",
            ">> I'd score this model response as 40 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The model correctly identifies that thunderstorms are related to clouds (correctly identifying the type of phenomenon).\n",
            "* However, it incorrectly specifies the type of cloud associated with thunderstorms. Cumulus clouds are not typically associated with thunderstorms; cumulonimbus clouds are.\n",
            "* The response lacks precision and accuracy in its description.\n",
            "\n",
            "Overall, while the model attempts to address the question, it provides an incorrect answer, which is why I'd score it as 40 out of 100.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "Score:\n",
            ">> I'd rate my own response as 95 out of 100. Here's why:\n",
            "\n",
            "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
            "* The response is concise and clear, making it easy to understand.\n",
            "* There are no grammatical errors or ambiguities that could lead to confusion.\n",
            "\n",
            "The only reason I wouldn't give myself a perfect score is that the response is slightly redundant - the instruction already states \"Name the author of 'Pride and Prejudice'\", so the response doesn't add any new information. However, this is a minor quibble, and overall, I think my response is effective in answering the question.\n",
            "\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "for entry in test_data[:3]:\n",
        "    prompt = (\n",
        "        f\"Given the input `{format_input(entry)}` \"\n",
        "        f\"and correct output `{entry['output']}`, \"\n",
        "        f\"score the model response `{entry['model_response']}`\"\n",
        "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "    )\n",
        "    print(\"\\nDataset response:\")\n",
        "    print(\">>\", entry['output'])\n",
        "    print(\"\\nModel response:\")\n",
        "    print(\">>\", entry[\"model_response\"])\n",
        "    print(\"\\nScore:\")\n",
        "    print(\">>\", query_model(prompt))\n",
        "    print(\"\\n-------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32ba7eeb",
      "metadata": {},
      "source": [
        "## LLM-as-Judge: Full Test Set Scoring\n",
        "\n",
        "Score all test entries with `generate_model_scores`; compute average. Expects judge to respond with integer only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f4925183",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring entries: 100%|| 110/110 [08:51<00:00,  4.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of scores: 110 of 110\n",
            "Average score: 47.86\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score = query_model(prompt, model)\n",
        "        try:\n",
        "            scores.append(int(score))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert score: {score}\")\n",
        "            continue\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "scores = generate_model_scores(test_data, \"model_response\")\n",
        "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
        "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
